{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%cython\n",
    "\n",
    "from pandas import DataFrame, read_sas, read_csv\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "cimport numpy as np\n",
    "\n",
    "from SECEdgar.crawler import SecCrawler\n",
    "\n",
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "import time\n",
    "from datetime import datetime as dt\n",
    "from datetime import date\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import os\n",
    "import re\n",
    "import lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 2s, sys: 11.1 s, total: 3min 13s\n",
      "Wall time: 3min 13s\n"
     ]
    }
   ],
   "source": [
    "# Read in SAS data set - takes a while...\n",
    "%time data = read_sas(\"data/crsp_comp.sas7bdat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 677 Âµs, sys: 15.5 ms, total: 16.2 ms\n",
      "Wall time: 15.3 ms\n",
      "CPU times: user 3.55 ms, sys: 24 ms, total: 27.5 ms\n",
      "Wall time: 27.5 ms\n",
      "CPU times: user 14.1 ms, sys: 70.2 ms, total: 84.3 ms\n",
      "Wall time: 84.9 ms\n",
      "CPU times: user 2.86 ms, sys: 150 ms, total: 153 ms\n",
      "Wall time: 152 ms\n"
     ]
    }
   ],
   "source": [
    "# Read in the positive word list\n",
    "%time pos_list = read_csv(\"data/pos_list.csv\", header=None, names=['word'])\n",
    "%time pos_roots = read_csv(\"data/pos_roots.csv\")\n",
    "pos_roots_dict = dict(zip(list(pos_roots.word), list(pos_roots.group)))\n",
    "\n",
    "# Read in the negative word list\n",
    "%time neg_list = read_csv(\"data/neg_list.csv\", header=None, names=['word'])\n",
    "%time neg_roots = read_csv(\"data/neg_roots.csv\")\n",
    "neg_roots_dict = dict(zip(list(neg_roots.word), list(neg_roots.group)))\n",
    "\n",
    "# Turn them into a Series for easier lookups later on\n",
    "pos_list = pos_list.iloc[:]\n",
    "neg_list = neg_list.iloc[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Sort the set by cusip, permno, cik, and then year (descending)\n",
    "data.sort_values(['CUSIP', 'PERMNO', 'cik', 'year'], ascending=[True, True, True, False], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Remove any duplicates where CUSIP, PERMNO, and CIK match\n",
    "ciks = data.drop_duplicates(subset=['CUSIP', 'PERMNO', 'cik'])\n",
    "\n",
    "# Only keep the cik and ticker column\n",
    "ciks = ciks[['cik', 'tic']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "# Iterate over each CIK and pull the relevant 10k filings\n",
    "crawler = SecCrawler()\n",
    "end_date = '20081231'\n",
    "count = '20'\n",
    "\n",
    "for index, row in ciks.iterrows():\n",
    "    cik = row.iloc[0]\n",
    "    tic = row.iloc[1]\n",
    "    crawler.filing_10K(tic, cik, end_date, count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%cython\n",
    "import cPickle as pickle\n",
    "\n",
    "cdef void cache_objects(dict objs, int count, int batch):\n",
    "    if count % batch == 0:\n",
    "        print(\"Count: \" + str(count))\n",
    "        for name, obj in objs.iteritems():\n",
    "            print(\"Saving the \" + name + \" object...\")\n",
    "            pickle.dump(obj, open(\"data/\" + name + \".p\", \"wb\"))\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count: 1\n",
      "Saving the test object...\n",
      "Saving the test2 object...\n",
      " "
     ]
    }
   ],
   "source": [
    "%prun -l 4 cache_objects({'test': processed, 'test2': DataFrame()}, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1) Processing SEC-Edgar-data/3MCLN./0000789547/10-K/0000948830-96-000019.txt\n",
      "(2) Processing SEC-Edgar-data/3MCLN./0000789547/10-K/0000948830-97-000002.txt\n",
      "(3) Processing SEC-Edgar-data/ITGB/0000320573/10-K/0000320573-96-000138.txt\n",
      "(4) Processing SEC-Edgar-data/ITGB/0000320573/10-K/0000320573-05-000040.txt\n",
      "(5) Processing SEC-Edgar-data/ITGB/0000320573/10-K/0000320573-04-000055.txt\n",
      "(6) Processing SEC-Edgar-data/ITGB/0000320573/10-K/0000320573-01-500016.txt\n",
      "(7) Processing SEC-Edgar-data/ITGB/0000320573/10-K/0000320573-00-000006.txt\n",
      "(8) Processing SEC-Edgar-data/ITGB/0000320573/10-K/0000320573-95-000097.txt\n",
      "(9) Processing SEC-Edgar-data/ITGB/0000320573/10-K/0000320573-00-000023.txt\n",
      "(10) Processing SEC-Edgar-data/ITGB/0000320573/10-K/0000320573-98-000032.txt\n",
      "(11) Processing SEC-Edgar-data/ITGB/0000320573/10-K/0000320573-02-000026.txt\n",
      "(12) Processing SEC-Edgar-data/ITGB/0000320573/10-K/0000320573-06-000032.txt\n",
      "(13) Processing SEC-Edgar-data/ITGB/0000320573/10-K/0000320573-98-000022.txt\n",
      "(14) Processing SEC-Edgar-data/ITGB/0000320573/10-K/0000320573-07-000005.txt\n",
      "(15) Processing SEC-Edgar-data/ITGB/0000320573/10-K/0000320573-03-000024.txt\n",
      "(16) Processing SEC-Edgar-data/FRPT.1/0001032863/10-K/0001047469-08-010069.txt\n",
      "(17) Processing SEC-Edgar-data/FRPT.1/0001032863/10-K/0001104659-07-020122.txt\n",
      "(18) Processing SEC-Edgar-data/FRPT.1/0001032863/10-K/0001104659-06-025030.txt\n",
      "(19) Processing SEC-Edgar-data/CEC/0000813920/10-K/0000813920-00-000001.txt\n",
      "(20) Processing SEC-Edgar-data/CEC/0000813920/10-K/0000950134-01-002905.txt\n",
      "(21) Processing SEC-Edgar-data/CEC/0000813920/10-K/0000813920-03-000031.txt\n",
      "(22) Processing SEC-Edgar-data/CEC/0000813920/10-K/0000813920-05-000051.txt\n",
      "(23) Processing SEC-Edgar-data/CEC/0000813920/10-K/0000813920-99-000001.txt\n",
      "(24) Processing SEC-Edgar-data/CEC/0000813920/10-K/0000813920-97-000001.txt\n",
      "(25) Processing SEC-Edgar-data/CEC/0000813920/10-K/0000813920-04-000026.txt\n",
      "(26) Processing SEC-Edgar-data/CEC/0000813920/10-K/0001193125-07-087737.txt\n",
      "(27) Processing SEC-Edgar-data/CEC/0000813920/10-K/0001193125-08-041943.txt\n",
      "(28) Processing SEC-Edgar-data/CEC/0000813920/10-K/0000813920-06-000040.txt\n",
      "(29) Processing SEC-Edgar-data/CEC/0000813920/10-K/0000813920-96-000001.txt\n",
      "(30) Processing SEC-Edgar-data/CEC/0000813920/10-K/0000813920-98-000001.txt\n",
      "(31) Processing SEC-Edgar-data/CEC/0000813920/10-K/0001193125-07-087698.txt\n",
      "Amended 10-K - moved file\n",
      "(32) Processing SEC-Edgar-data/LHSG/0001032330/10-K/0000950144-00-003903.txt\n",
      "(33) Processing SEC-Edgar-data/LHSG/0001032330/10-K/0001021408-99-000587.txt\n",
      "(34) Processing SEC-Edgar-data/LHSG/0001032330/10-K/0000931763-98-000698.txt\n",
      "(35) Processing SEC-Edgar-data/SSAXQ/0000808207/10-K/0000950131-97-000470.txt\n",
      "(36) Processing SEC-Edgar-data/SSAXQ/0000808207/10-K/0000950131-97-000472.txt\n",
      "(37) Processing SEC-Edgar-data/SSAXQ/0000808207/10-K/0000950131-98-000453.txt\n",
      "(38) Processing SEC-Edgar-data/SSAXQ/0000808207/10-K/0000950131-99-000459.txt\n",
      "(39) Processing SEC-Edgar-data/SSAXQ/0000808207/10-K/0000950131-96-000087.txt\n",
      "(40) Processing SEC-Edgar-data/SSAXQ/0000808207/10-K/0000950131-00-000575.txt\n",
      "(41) Processing SEC-Edgar-data/OCNB.1/0001182555/10-K/0000882377-05-000649.txt\n",
      "(42) Processing SEC-Edgar-data/OCNB.1/0001182555/10-K/0000882377-06-001096.txt\n",
      "(43) Processing SEC-Edgar-data/3LBCP/0001353268/10-K/0001144204-07-069634.txt\n",
      "(44) Processing SEC-Edgar-data/3LBCP/0001353268/10-K/0001144204-06-054438.txt\n",
      "(45) Processing SEC-Edgar-data/3LBCP/0001353268/10-K/0001144204-08-071272.txt\n",
      "(46) Processing SEC-Edgar-data/HEIIQ/0000351298/10-K/0000950134-05-000705.txt\n",
      "(47) Processing SEC-Edgar-data/HEIIQ/0000351298/10-K/0000950134-03-016691.txt\n",
      "(48) Processing SEC-Edgar-data/HEIIQ/0000351298/10-K/0000950137-01-504448.txt\n",
      "(49) Processing SEC-Edgar-data/HEIIQ/0000351298/10-K/0000950137-07-018080.txt\n",
      "(50) Processing SEC-Edgar-data/HEIIQ/0000351298/10-K/0000950134-02-015669.txt\n",
      "Count: 50\n",
      "Saving the filings object...\n",
      "Saving the processed object...\n",
      "(51) Processing SEC-Edgar-data/HEIIQ/0000351298/10-K/0000950134-05-022206.txt\n",
      "(52) Processing SEC-Edgar-data/HEIIQ/0000351298/10-K/0000950137-01-505139.txt\n",
      "(53) Processing SEC-Edgar-data/HEIIQ/0000351298/10-K/0000950137-06-013087.txt\n",
      "(54) Processing SEC-Edgar-data/RAYM/0000082231/10-K/0000950116-96-000199.txt\n",
      "(55) Processing SEC-Edgar-data/RAYM/0000082231/10-K/0000950116-97-000729.txt\n",
      "(56) Processing SEC-Edgar-data/LUK/0000096223/10-K/0000096223-08-000015.txt\n",
      "(57) Processing SEC-Edgar-data/LUK/0000096223/10-K/0000909518-05-000159.txt\n",
      "(58) Processing SEC-Edgar-data/LUK/0000096223/10-K/0000909518-06-000302.txt\n",
      "Amended 10-K - moved file\n",
      "(59) Processing SEC-Edgar-data/3LTWO/0000920038/10-K/0000912057-00-014840.txt\n",
      "(60) Processing SEC-Edgar-data/3LTWO/0000920038/10-K/0000930661-99-000641.txt\n",
      "(61) Processing SEC-Edgar-data/3LTWO/0000920038/10-K/0000930661-98-000829.txt\n",
      "(62) Processing SEC-Edgar-data/3LTWO/0000920038/10-K/0000912057-01-508658.txt\n",
      "(63) Processing SEC-Edgar-data/3LTWO/0000920038/10-K/0000930661-97-000753.txt\n",
      "(64) Processing SEC-Edgar-data/3LTWO/0000920038/10-K/0000930661-97-001105.txt\n",
      "Amended 10-K - moved file\n",
      "(65) Processing SEC-Edgar-data/AEY/0000874292/10-K/0001355856-08-000044.txt\n",
      "(66) Processing SEC-Edgar-data/AEY/0000874292/10-K/0001355856-07-000062.txt\n",
      "(67) Processing SEC-Edgar-data/AEY/0000874292/10-K/0001193125-05-249751.txt\n",
      "(68) Processing SEC-Edgar-data/AEY/0000874292/10-K/0001355856-06-000049.txt\n",
      "(69) Processing SEC-Edgar-data/AEY/0000874292/10-K/0001157523-04-011718.txt\n",
      "(70) Processing SEC-Edgar-data/NBIX/0000914475/10-K/0000936392-03-000214.txt\n",
      "(71) Processing SEC-Edgar-data/NBIX/0000914475/10-K/0000914475-00-000010.txt\n",
      "(72) Processing SEC-Edgar-data/NBIX/0000914475/10-K/0000898430-02-001036.txt\n",
      "(73) Processing SEC-Edgar-data/NBIX/0000914475/10-K/0000936392-06-000084.txt\n",
      "(74) Processing SEC-Edgar-data/NBIX/0000914475/10-K/0000891618-98-001665.txt\n",
      "(75) Processing SEC-Edgar-data/NBIX/0000914475/10-K/0000936392-04-000211.txt\n",
      "(76) Processing SEC-Edgar-data/NBIX/0000914475/10-K/0001021408-00-003842.txt\n",
      "Amended 10-K - moved file\n",
      "(77) Processing SEC-Edgar-data/MGT/0001001601/10-K/0001104659-07-024175.txt\n",
      "(78) Processing SEC-Edgar-data/MGT/0001001601/10-K/0001047469-04-011287.txt\n",
      "(79) Processing SEC-Edgar-data/MGT/0001001601/10-K/0001047469-03-013236.txt\n",
      "(80) Processing SEC-Edgar-data/MGT/0001001601/10-K/0001104659-08-017955.txt\n",
      "(81) Processing SEC-Edgar-data/MGT/0001001601/10-K/0001104659-06-020099.txt\n",
      "(82) Processing SEC-Edgar-data/MGT/0001001601/10-K/0001104659-08-068271.txt\n",
      "Amended 10-K - moved file\n",
      "(83) Processing SEC-Edgar-data/PIK./0001094286/10-K/0001047469-04-007160.txt\n",
      "(84) Processing SEC-Edgar-data/PIK./0001094286/10-K/0001095811-00-000798.txt\n",
      "(85) Processing SEC-Edgar-data/PIK./0001094286/10-K/0001047469-03-008786.txt\n",
      "(86) Processing SEC-Edgar-data/PIK./0001094286/10-K/0001047469-04-037052.txt\n",
      "(87) Processing SEC-Edgar-data/PIK./0001094286/10-K/0000912057-02-010962.txt\n",
      "(88) Processing SEC-Edgar-data/PIK./0001094286/10-K/0001047469-05-028235.txt\n",
      "(89) Processing SEC-Edgar-data/PIK./0001094286/10-K/0001095811-01-001660.txt\n",
      "(90) Processing SEC-Edgar-data/AHPI/0000874710/10-K/0001014858-97-000079.txt\n",
      "(91) Processing SEC-Edgar-data/AHPI/0000874710/10-K/0001015402-98-000350.txt\n",
      "(92) Processing SEC-Edgar-data/AHPI/0000874710/10-K/0000950137-07-014817.txt\n",
      "(93) Processing SEC-Edgar-data/AHPI/0000874710/10-K/0000950134-01-506871.txt\n",
      "(94) Processing SEC-Edgar-data/AHPI/0000874710/10-K/0000950137-08-012047.txt\n",
      "(95) Processing SEC-Edgar-data/AHPI/0000874710/10-K/0000950137-05-011842.txt\n",
      "(96) Processing SEC-Edgar-data/AHPI/0000874710/10-K/0001015402-98-000351.txt\n",
      "Amended 10-K - moved file\n",
      "(97) Processing SEC-Edgar-data/IXYS/0000945699/10-K/0000950008-98-000151.txt\n",
      "(98) Processing SEC-Edgar-data/IXYS/0000945699/10-K/0000950134-07-018397.txt\n",
      "Amended 10-K - moved file\n",
      "(99) Processing SEC-Edgar-data/UDI/0001051719/10-K/0000950133-05-000956.txt\n",
      "(100) Processing SEC-Edgar-data/UDI/0001051719/10-K/0000928385-01-502787.txt\n",
      "Amended 10-K - moved file\n",
      "(101) Processing SEC-Edgar-data/OSIP/0000729922/10-K/0000950123-02-011721.txt\n",
      "(102) Processing SEC-Edgar-data/OSIP/0000729922/10-K/0000950123-08-002273.txt\n",
      "(103) Processing SEC-Edgar-data/OSIP/0000729922/10-K/0000950123-06-003601.txt\n",
      "Amended 10-K - moved file\n",
      "(104) Processing SEC-Edgar-data/SST.1/0000821530/10-K/0000821530-97-000009.txt\n",
      "(105) Processing SEC-Edgar-data/SST.1/0000821530/10-K/0000821530-96-000006.txt\n",
      "(106) Processing SEC-Edgar-data/LEDR/0001298978/10-K/0001193125-05-044575.txt\n",
      "(107) Processing SEC-Edgar-data/LEDR/0001298978/10-K/0001193125-06-050914.txt\n",
      "(108) Processing SEC-Edgar-data/LEDR/0001298978/10-K/0001193125-07-045677.txt\n",
      "(109) Processing SEC-Edgar-data/LEDR/0001298978/10-K/0001193125-08-053977.txt\n",
      "(110) Processing SEC-Edgar-data/SKIL./0001094451/10-K/0000950135-02-002183.txt\n",
      "(111) Processing SEC-Edgar-data/SKIL./0001094451/10-K/0000950135-01-500917.txt\n",
      "(112) Processing SEC-Edgar-data/SKIL./0001094451/10-K/0000950135-01-502115.txt\n",
      "Amended 10-K - moved file\n",
      "(113) Processing SEC-Edgar-data/ABLSQ/0000857171/10-K/0000950135-98-002444.txt\n",
      "(114) Processing SEC-Edgar-data/ABLSQ/0000857171/10-K/0001072613-02-000516.txt\n",
      "(115) Processing SEC-Edgar-data/ABLSQ/0000857171/10-K/0000950135-98-005078.txt\n",
      "Amended 10-K - moved file\n",
      "(116) Processing SEC-Edgar-data/KDN/0000740694/10-K/0000950124-01-001695.txt\n",
      "(117) Processing SEC-Edgar-data/KDN/0000740694/10-K/0000950124-03-000773.txt\n",
      "(118) Processing SEC-Edgar-data/KDN/0000740694/10-K/0000950144-96-001114.txt\n",
      "(119) Processing SEC-Edgar-data/KDN/0000740694/10-K/0000950124-05-001449.txt\n",
      "(120) Processing SEC-Edgar-data/KDN/0000740694/10-K/0000950144-95-000799.txt\n",
      "(121) Processing SEC-Edgar-data/KDN/0000740694/10-K/0000950144-97-002833.txt\n",
      "(122) Processing SEC-Edgar-data/KDN/0000740694/10-K/0000950124-06-000951.txt\n",
      "(123) Processing SEC-Edgar-data/KDN/0000740694/10-K/0000950124-08-000899.txt\n",
      "(124) Processing SEC-Edgar-data/KDN/0000740694/10-K/0000950144-98-003367.txt\n",
      "(125) Processing SEC-Edgar-data/KDN/0000740694/10-K/0000950124-02-000848.txt\n",
      "(126) Processing SEC-Edgar-data/KDN/0000740694/10-K/0000950144-99-003410.txt\n",
      "(127) Processing SEC-Edgar-data/KDN/0000740694/10-K/0000950144-94-000675.txt\n",
      "Out of date range - moved file.\n",
      "(128) Processing SEC-Edgar-data/ATEA/0000945989/10-K/0000950159-04-000363.txt\n",
      "Out of date range - moved file.\n",
      "(129) Processing SEC-Edgar-data/ESL/0000033619/10-K/0001193125-07-003012.txt\n",
      "Out of date range - moved file.\n",
      "(130) Processing SEC-Edgar-data/UTCIQ/0000890096/10-K/0000890096-99-000022.txt\n",
      "(131) Processing SEC-Edgar-data/UTCIQ/0000890096/10-K/0000890096-96-000044.txt\n",
      "(132) Processing SEC-Edgar-data/UTCIQ/0000890096/10-K/0000890096-01-500025.txt\n",
      "(133) Processing SEC-Edgar-data/UTCIQ/0000890096/10-K/0000890096-03-000002.txt\n",
      "(134) Processing SEC-Edgar-data/UTCIQ/0000890096/10-K/0000890096-00-000049.txt\n",
      "(135) Processing SEC-Edgar-data/UTCIQ/0000890096/10-K/0000890096-02-000002.txt\n",
      "Amended 10-K - moved file\n",
      "(136) Processing SEC-Edgar-data/TTRR/0000829221/10-K/0000829221-98-000004.txt\n",
      "(137) Processing SEC-Edgar-data/TTRR/0000829221/10-K/0000829221-97-000008.txt\n",
      "(138) Processing SEC-Edgar-data/SYD.1/0001121302/10-K/0001193125-05-242523.txt\n",
      "(139) Processing SEC-Edgar-data/SYD.1/0001121302/10-K/0000892569-03-002873.txt\n",
      "(140) Processing SEC-Edgar-data/SYD.1/0001121302/10-K/0001193125-04-212750.txt\n",
      "(141) Processing SEC-Edgar-data/SYD.1/0001121302/10-K/0000950124-00-007640.txt\n",
      "(142) Processing SEC-Edgar-data/SYD.1/0001121302/10-K/0000950134-02-015766.txt\n",
      "(143) Processing SEC-Edgar-data/SYD.1/0001121302/10-K/0000950124-01-504430.txt\n",
      "(144) Processing SEC-Edgar-data/GHM/0000716314/10-K/0000950152-06-005026.txt\n",
      "(145) Processing SEC-Edgar-data/GHM/0000716314/10-K/0000716314-96-000002.txt\n",
      "(146) Processing SEC-Edgar-data/GHM/0000716314/10-K/0000950152-00-004763.txt\n",
      "(147) Processing SEC-Edgar-data/GHM/0000716314/10-K/0000950134-08-010593.txt\n",
      "(148) Processing SEC-Edgar-data/GHM/0000716314/10-K/0000950152-98-005579.txt\n",
      "(149) Processing SEC-Edgar-data/GHM/0000716314/10-K/0000950152-07-004921.txt\n",
      "(150) Processing SEC-Edgar-data/GHM/0000716314/10-K/0000950152-99-005465.txt\n",
      "Count: 150\n",
      "Saving the filings object...\n",
      "Saving the processed object...\n",
      "(151) Processing SEC-Edgar-data/GHM/0000716314/10-K/0000950152-05-007748.txt\n",
      "Amended 10-K - moved file\n",
      "(152) Processing SEC-Edgar-data/BWN.2/0001020898/10-K/0001020898-00-000013.txt\n",
      "(153) Processing SEC-Edgar-data/BWN.2/0001020898/10-K/0001020898-99-000002.txt\n",
      "(154) Processing SEC-Edgar-data/KMG/0001028215/10-K/0000912057-01-536445.txt\n",
      "(155) Processing SEC-Edgar-data/KMG/0001028215/10-K/0001104659-05-051223.txt\n",
      "(156) Processing SEC-Edgar-data/KMG/0001028215/10-K/0001104659-03-023612.txt\n",
      "(157) Processing SEC-Edgar-data/KMG/0001028215/10-K/0001104659-04-030510.txt\n",
      "(158) Processing SEC-Edgar-data/KMG/0001028215/10-K/0001104659-08-064092.txt\n",
      "(159) Processing SEC-Edgar-data/KMG/0001028215/10-K/0001104659-07-075098.txt\n",
      "(160) Processing SEC-Edgar-data/KMG/0001028215/10-K/0001104659-06-067949.txt\n",
      "(161) Processing SEC-Edgar-data/KMG/0001028215/10-K/0000912057-02-039044.txt\n",
      "(162) Processing SEC-Edgar-data/ZOLL/0000887568/10-K/0000950135-97-005183.txt\n",
      "(163) Processing SEC-Edgar-data/ZOLL/0000887568/10-K/0000950135-00-005572.txt\n",
      "(164) Processing SEC-Edgar-data/ZOLL/0000887568/10-K/0000950135-01-504035.txt\n",
      "(165) Processing SEC-Edgar-data/ZOLL/0000887568/10-K/0001193125-04-219292.txt\n",
      "Amended 10-K - moved file\n",
      "(166) Processing SEC-Edgar-data/DETC/0000028365/10-K/0000028365-00-000006.txt\n",
      "(167) Processing SEC-Edgar-data/DETC/0000028365/10-K/0000028365-99-000006.txt\n",
      "(168) Processing SEC-Edgar-data/DETC/0000028365/10-K/0000028365-96-000018.txt\n",
      "(169) Processing SEC-Edgar-data/DETC/0000028365/10-K/0000028365-98-000010.txt\n",
      "(170) Processing SEC-Edgar-data/DETC/0000028365/10-K/0000028365-97-000004.txt\n",
      "(171) Processing SEC-Edgar-data/DETC/0000028365/10-K/0000028365-95-000005.txt\n",
      "(172) Processing SEC-Edgar-data/DETC/0000028365/10-K/0000028365-00-000005.txt\n",
      "(173) Processing SEC-Edgar-data/DETC/0000028365/10-K/0000028365-96-000017.txt\n",
      "(174) Processing SEC-Edgar-data/SHRPQ/0000811696/10-K/0001193125-06-095411.txt\n",
      "(175) Processing SEC-Edgar-data/SHRPQ/0000811696/10-K/0001047469-03-015102.txt\n",
      "(176) Processing SEC-Edgar-data/SHRPQ/0000811696/10-K/0000950005-97-000472.txt\n",
      "(177) Processing SEC-Edgar-data/SHRPQ/0000811696/10-K/0001193125-07-127055.txt\n",
      "(178) Processing SEC-Edgar-data/SHRPQ/0000811696/10-K/0000950005-04-000375.txt\n",
      "(179) Processing SEC-Edgar-data/SHRPQ/0000811696/10-K/0000950005-96-000209.txt\n",
      "(180) Processing SEC-Edgar-data/SHRPQ/0000811696/10-K/0000950005-00-000590.txt\n",
      "(181) Processing SEC-Edgar-data/SHRPQ/0000811696/10-K/0000950005-02-000484.txt\n",
      "(182) Processing SEC-Edgar-data/SHRPQ/0000811696/10-K/0000950005-99-000397.txt\n",
      "(183) Processing SEC-Edgar-data/SHRPQ/0000811696/10-K/0000950005-01-500034.txt\n",
      "(184) Processing SEC-Edgar-data/SHRPQ/0000811696/10-K/0001193125-05-094140.txt\n",
      "(185) Processing SEC-Edgar-data/SHRPQ/0000811696/10-K/0000950005-98-000416.txt\n",
      "(186) Processing SEC-Edgar-data/SHRPQ/0000811696/10-K/0001193125-07-044537.txt\n",
      "Amended 10-K - moved file\n",
      "(187) Processing SEC-Edgar-data/ANSS/0001013462/10-K/0000950132-02-000032.txt\n",
      "(188) Processing SEC-Edgar-data/ANSS/0001013462/10-K/0001193125-08-041214.txt\n",
      "(189) Processing SEC-Edgar-data/ANSS/0001013462/10-K/0000950132-97-000207.txt\n",
      "(190) Processing SEC-Edgar-data/ANSS/0001013462/10-K/0001193125-07-042422.txt\n",
      "(191) Processing SEC-Edgar-data/ANSS/0001013462/10-K/0000950132-01-000198.txt\n",
      "(192) Processing SEC-Edgar-data/ANSS/0001013462/10-K/0001193125-06-049706.txt\n",
      "(193) Processing SEC-Edgar-data/ANSS/0001013462/10-K/0000950132-00-000213.txt\n",
      "(194) Processing SEC-Edgar-data/ANSS/0001013462/10-K/0001193125-05-046539.txt\n",
      "(195) Processing SEC-Edgar-data/ANSS/0001013462/10-K/0000950132-98-000250.txt\n",
      "(196) Processing SEC-Edgar-data/ANSS/0001013462/10-K/0000950132-99-000268.txt\n",
      "(197) Processing SEC-Edgar-data/ANSS/0001013462/10-K/0001193125-04-040366.txt\n",
      "(198) Processing SEC-Edgar-data/ANSS/0001013462/10-K/0001193125-06-070111.txt\n",
      "Amended 10-K - moved file\n",
      "(199) Processing SEC-Edgar-data/JOSEA/0000054050/10-K/0001045969-99-000217.txt\n",
      "(200) Processing SEC-Edgar-data/JOSEA/0000054050/10-K/0000950131-95-002629.txt\n",
      "Count: 200\n",
      "Saving the filings object...\n",
      "Saving the processed object...\n",
      "(201) Processing SEC-Edgar-data/JOSEA/0000054050/10-K/0000950131-97-002064.txt\n",
      "(202) Processing SEC-Edgar-data/JOSEA/0000054050/10-K/0001045969-01-000360.txt\n",
      "(203) Processing SEC-Edgar-data/JOSEA/0000054050/10-K/0000950131-96-004719.txt\n",
      "(204) Processing SEC-Edgar-data/JOSEA/0000054050/10-K/0001045969-02-000539.txt\n",
      "(205) Processing SEC-Edgar-data/JOSEA/0000054050/10-K/0000054050-94-000013.txt\n",
      "Out of date range - moved file.\n",
      "(206) Processing SEC-Edgar-data/PHIIK/0000350403/10-K/0000950129-04-001293.txt\n",
      "Out of date range - moved file.\n",
      "(207) Processing SEC-Edgar-data/HMP/0001052958/10-K/0000950144-99-003802.txt\n",
      "(208) Processing SEC-Edgar-data/HMP/0001052958/10-K/0000950144-02-003943.txt\n",
      "(209) Processing SEC-Edgar-data/HMP/0001052958/10-K/0000950144-00-004015.txt\n",
      "(210) Processing SEC-Edgar-data/HMP/0001052958/10-K/0000950144-03-004001.txt\n",
      "(211) Processing SEC-Edgar-data/HMP/0001052958/10-K/0000950144-04-003233.txt\n",
      "(212) Processing SEC-Edgar-data/HMP/0001052958/10-K/0000950144-01-004696.txt\n",
      "(213) Processing SEC-Edgar-data/HMP/0001052958/10-K/0000950144-04-004562.txt\n",
      "Amended 10-K - moved file\n",
      "(214) Processing SEC-Edgar-data/AMSWA/0000713425/10-K/0001193125-05-201867.txt\n",
      "(215) Processing SEC-Edgar-data/AMSWA/0000713425/10-K/0000931763-01-501108.txt\n",
      "(216) Processing SEC-Edgar-data/AMSWA/0000713425/10-K/0000931763-98-001962.txt\n",
      "(217) Processing SEC-Edgar-data/AMSWA/0000713425/10-K/0001193125-04-118173.txt\n",
      "(218) Processing SEC-Edgar-data/AMSWA/0000713425/10-K/0000931763-97-001218.txt\n",
      "(219) Processing SEC-Edgar-data/AMSWA/0000713425/10-K/0000931763-97-001258.txt\n",
      "(220) Processing SEC-Edgar-data/AMSWA/0000713425/10-K/0001193125-07-155732.txt\n",
      "(221) Processing SEC-Edgar-data/AMSWA/0000713425/10-K/0000931763-98-001948.txt\n",
      "(222) Processing SEC-Edgar-data/AMSWA/0000713425/10-K/0001193125-06-147073.txt\n",
      "(223) Processing SEC-Edgar-data/AMSWA/0000713425/10-K/0000931763-02-002541.txt\n",
      "(224) Processing SEC-Edgar-data/AMSWA/0000713425/10-K/0001193125-03-024760.txt\n",
      "(225) Processing SEC-Edgar-data/AMSWA/0000713425/10-K/0001193125-08-150516.txt\n",
      "(226) Processing SEC-Edgar-data/AMSWA/0000713425/10-K/0000931763-00-001768.txt\n",
      "(227) Processing SEC-Edgar-data/AMSWA/0000713425/10-K/0000931763-99-002165.txt\n",
      "(228) Processing SEC-Edgar-data/AMSWA/0000713425/10-K/0000950109-96-004710.txt\n",
      "(229) Processing SEC-Edgar-data/AMSWA/0000713425/10-K/0001193125-03-091371.txt\n",
      "Amended 10-K - moved file\n",
      "(230) Processing SEC-Edgar-data/IDYN/0000822084/10-K/0000891618-00-002404.txt\n",
      "(231) Processing SEC-Edgar-data/IDYN/0000822084/10-K/0000891618-00-001641.txt\n",
      "(232) Processing SEC-Edgar-data/IDYN/0000822084/10-K/0000891618-98-001597.txt\n",
      "(233) Processing SEC-Edgar-data/IDYN/0000822084/10-K/0000912057-97-010916.txt\n",
      "(234) Processing SEC-Edgar-data/IDYN/0000822084/10-K/0000891618-98-001393.txt\n",
      "(235) Processing SEC-Edgar-data/IDYN/0000822084/10-K/0000891618-99-001264.txt\n",
      "(236) Processing SEC-Edgar-data/SNWL/0001093885/10-K/0001012870-02-001604.txt\n",
      "(237) Processing SEC-Edgar-data/SNWL/0001093885/10-K/0000950134-08-004440.txt\n",
      "(238) Processing SEC-Edgar-data/SNWL/0001093885/10-K/0001193125-04-040935.txt\n",
      "(239) Processing SEC-Edgar-data/SNWL/0001093885/10-K/0001012870-01-001012.txt\n",
      "(240) Processing SEC-Edgar-data/SNWL/0001093885/10-K/0001012870-01-501602.txt\n",
      "Amended 10-K - moved file\n",
      "(241) Processing SEC-Edgar-data/CENF/0001085636/10-K/0001085636-05-000014.txt\n",
      "(242) Processing SEC-Edgar-data/CENF/0001085636/10-K/0000891092-04-001482.txt\n",
      "(243) Processing SEC-Edgar-data/CENF/0001085636/10-K/0001008886-06-000087.txt\n",
      "Amended 10-K - moved file\n",
      "(244) Processing SEC-Edgar-data/3DMSCE/0001048897/10-K/0001005477-99-003374.txt\n",
      "(245) Processing SEC-Edgar-data/3DMSCE/0001048897/10-K/0000891554-99-000749.txt\n",
      "(246) Processing SEC-Edgar-data/3DMSCE/0001048897/10-K/0001005477-00-001970.txt\n",
      "(247) Processing SEC-Edgar-data/3DMSCE/0001048897/10-K/0000950144-98-005606.txt\n",
      "(248) Processing SEC-Edgar-data/3DMSCE/0001048897/10-K/0000891554-99-000843.txt\n",
      "Amended 10-K - moved file\n",
      "(249) Processing SEC-Edgar-data/NPPI/0000902793/10-K/0000950129-97-005061.txt\n",
      "(250) Processing SEC-Edgar-data/NPPI/0000902793/10-K/0001010549-96-000307.txt\n",
      "Count: 250\n",
      "Saving the filings object...\n",
      "Saving the processed object...\n",
      "(251) Processing SEC-Edgar-data/IDT/0001005731/10-K/0000950130-00-005710.txt\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "u'distinction'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-2872b47d3b4e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnegated\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m                         \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpos_roots_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m                         \u001b[0mpos_occurs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mneg_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: u'distinction'"
     ]
    }
   ],
   "source": [
    "import cPickle as pickle\n",
    "\n",
    "# Pull in one file to start working on the parsing algorithm\n",
    "try:\n",
    "    filings = pickle.load(open(\"data/filings.p\", \"rb\"))\n",
    "except:\n",
    "    filings = DataFrame()\n",
    "    \n",
    "try:\n",
    "    processed = pickle.load(open(\"data/processed.p\", \"rb\"))    \n",
    "except:\n",
    "    processed = set()\n",
    "    \n",
    "# Batch save the filings info\n",
    "count = 0\n",
    "batch = 50\n",
    "file_count = 0\n",
    "\n",
    "# This is for testing\n",
    "stop = 100000\n",
    "skip_processed = True\n",
    "process = True\n",
    "\n",
    "folder = \"SEC-Edgar-data\"\n",
    "for (dirpath, dirnames, filenames) in os.walk(folder):\n",
    "    for filename in filenames:\n",
    "        file_count += 1\n",
    "        fn = os.sep.join([dirpath, filename])\n",
    "\n",
    "        if filename.endswith('.txt'):\n",
    "            # Skip this file if it exists in the filings object\n",
    "            if skip_processed and 'path' in filings.columns and fn in filings.path.values:\n",
    "            #if skip_processed and fn in processed:\n",
    "                #print(\"File already processed: \" + fn + \".\")\n",
    "                break\n",
    "\n",
    "            count += 1\n",
    "            if count > stop:\n",
    "                break\n",
    "\n",
    "            print(\"(\" + str(count) + \") Processing \" + fn)\n",
    "            tic = fn.split('/')[1]\n",
    "            cik = fn.split('/')[2]\n",
    "\n",
    "            # Open the file, get all of the content, and then pull it into a parser\n",
    "            fh = open(fn, 'r')\n",
    "            contents = fh.read()\n",
    "\n",
    "            # Clean up some of the text to fix malformed HTML before parsing it\n",
    "            malformed_tags = ['ACCEPTANCE-DATETIME', 'TYPE', 'SEQUENCE', 'FILENAME', 'DESCRIPTION']\n",
    "            for tag in malformed_tags:\n",
    "                # Do a regex that replaces all of these malformed tags in the document\n",
    "                regex = re.compile(r\"(\\n<%s>[^<]*?)\\n\" % re.escape(tag), re.I)\n",
    "                contents = regex.sub(r\"\\1</%s>\\n\" % tag, contents)\n",
    "\n",
    "            # Pull the 10-k into the parser\n",
    "            document = bs(contents, 'lxml')\n",
    "\n",
    "            # The document can either have a root node of sec-document or ims-document\n",
    "            if document.find('sec-document') is not None:\n",
    "                root = document.find('sec-document')\n",
    "            elif document.find('ims-document') is not None: \n",
    "                root = document.find('ims-document')\n",
    "            else:\n",
    "                root = document.find('document')\n",
    "\n",
    "            # Check if this is an amended 10-K and throw it out if so\n",
    "            type_text = root.find('type')\n",
    "            if type_text is None:\n",
    "                # Couldn't find the type so we move it to the _error folder\n",
    "                new_name = 'data/_error/' + tic + '-' + cik + '-' + filename\n",
    "\n",
    "                # Close the file so that we can move it\n",
    "                fh.close()\n",
    "                os.rename(fn, new_name)\n",
    "                print(\"Error finding type - moved file\")\n",
    "                break\n",
    "\n",
    "            elif type_text.text == '10-K/A':\n",
    "                # This is an amended 10-k, move it to the \"data/_amended\" folder\n",
    "                new_name = 'data/_amended/' + tic + '-' + cik + '-' + filename\n",
    "\n",
    "                # Close the file so that we can move it\n",
    "                fh.close()\n",
    "                os.rename(fn, new_name)\n",
    "                print(\"Amended 10-K - moved file\")\n",
    "                break\n",
    "\n",
    "            # Get the 'acceptance-datetime' metadata element\n",
    "            acc_dt = root.find('acceptance-datetime')\n",
    "            if acc_dt is None:\n",
    "                header_text = None\n",
    "                # If we didn't find an <acceptance-datetime /> element, find the date elsewhere\n",
    "                if root.find('sec-header') is not None:\n",
    "                    header_text = root.find('sec-header').text\n",
    "                elif root.find('ims-header') is not None:\n",
    "                    header_text = root.find('ims-header').text\n",
    "\n",
    "                if header_text:\n",
    "                    regex = re.compile(r\".*\\nFILED AS OF DATE:\\s+?([\\d]+?)\\n.*\", re.S)\n",
    "                    filing_dt_text = re.sub(regex, r\"\\1\", header_text)\n",
    "                    filing_dt = dt.strptime(filing_dt_text, '%Y%m%d')\n",
    "                    filing_ts = time.mktime(filing_dt.timetuple())\n",
    "                else:\n",
    "                    # We can't find the filing date for this file so throw it out\n",
    "                    new_name = 'data/_outofrange/' + tic + '-' + cik + '-' + filename\n",
    "\n",
    "                    # Close the file so that we can move it\n",
    "                    fh.close()\n",
    "                    os.rename(fn, new_name)\n",
    "                    print(\"Bad filing date - moved file\")\n",
    "                    break\n",
    "            else:\n",
    "                # Get the filing date\n",
    "                filing_dt_text = acc_dt.text.split('\\n', 1)[0][:8]\n",
    "\n",
    "            begin_dt = dt(1995, 1, 1)\n",
    "\n",
    "            # If the filing date is not within our date range, then move it\n",
    "            if begin_dt > filing_dt:\n",
    "                # This file is outside of our date range so move it\n",
    "                new_name = 'data/_outofrange/' + tic + '-' + cik + '-' + filename\n",
    "\n",
    "                # Close the file so that we can move it\n",
    "                fh.close()\n",
    "                os.rename(fn, new_name)\n",
    "                print(\"Out of date range - moved file.\")\n",
    "                break\n",
    "\n",
    "            # Remove the exhibits\n",
    "            #for doc in document.find('sec-document').findAll('document'):\n",
    "                #[ex.extract() for ex in docume]\n",
    "\n",
    "            # If we don't want to process the file, then we will quit here\n",
    "            if not process:\n",
    "                # Save this file as processed\n",
    "                processed.add(fn)\n",
    "                \n",
    "                # Save certain objects so we don't have to process everything again\n",
    "                objs = {'filings': filings, 'processed': processed}\n",
    "                cache_objects(objs, count, batch)\n",
    "                break\n",
    "\n",
    "            # Grab the report (and throw out images, tables)\n",
    "            report = root.find('text')\n",
    "\n",
    "            # Remove some elements\n",
    "            del_tags = ['img', 'hr', 'head']\n",
    "            for tag in del_tags:\n",
    "                [t.extract() for t in report.findAll(tag)]\n",
    "\n",
    "            strip_tags = ['b', 'i', 'u', 'sup', 'em', 'strong', 'font', 'p', 'div', 'td', 'tr', 'table', 'body', 'html']\n",
    "            for tag in strip_tags:\n",
    "                [t.replaceWithChildren() for t in report.findAll(tag)]\n",
    "\n",
    "            replace_tags = [{'br': '\\n'}]\n",
    "            for tag in replace_tags:\n",
    "                tag, replace = tag.popitem()\n",
    "                [t.replaceWith(replace) for t in report.findAll(tag)]\n",
    "\n",
    "            # Now that everything is cleaned up, we can run the word processing algorithm\n",
    "            pos_occurs = defaultdict(int)\n",
    "            neg_occurs = defaultdict(int)\n",
    "            negators = pd.Series(['not', 'no', 'never'])\n",
    "\n",
    "            # We will tokenize the text and iterate through each word\n",
    "            tokens = pd.Series(report.text.split())\n",
    "\n",
    "            # First, filter out words that aren't in the 12dictionary word list\n",
    "\n",
    "            # Now, process the text\n",
    "            for index, token in tokens.iteritems():\n",
    "                if token in pos_list.values:\n",
    "                    # Check to see if there is a negator\n",
    "                    negated = False\n",
    "                    for word in tokens.iloc[(index - 3):(index + 3)]:\n",
    "                        if word in negators.values:\n",
    "                            #print(\"Found a negator: \" + word + \" - \" + token)\n",
    "                            negated = True\n",
    "\n",
    "                    if not negated:\n",
    "                        root = pos_roots_dict[token]\n",
    "                        pos_occurs[root] += 1\n",
    "                elif token in neg_list.values:\n",
    "                    # Check to see if there is a negator\n",
    "                    negated = False\n",
    "                    for word in tokens.iloc[(index - 3):(index + 3)]:\n",
    "                        if word in negators.values:\n",
    "                            #print(\"Found a negator: \" + word + \" - \" + token)\n",
    "                            negated = True\n",
    "\n",
    "                    if not negated:\n",
    "                        root = neg_roots_dict[token]\n",
    "                        neg_occurs[root] += 1\n",
    "\n",
    "            # Add the info for this 10-K to the filings dataframe to keep track of it\n",
    "            filings = filings.append(\n",
    "                {'cik': cik,\n",
    "                 'tic': tic,\n",
    "                 'path': fn,\n",
    "                 'file_name': filename,\n",
    "                 'filing_date': filing_ts,\n",
    "                 'pos_occurs': pos_occurs,\n",
    "                 'neg_occurs': neg_occurs,\n",
    "                 'mtime': time.time()\n",
    "                }, ignore_index=True)\n",
    "\n",
    "            # Save this file as processed\n",
    "            processed.add(fn)\n",
    "\n",
    "            # Save certain objects so we don't have to process everything again\n",
    "            objs = {'filings': filings, 'processed': processed}\n",
    "            cache_objects(objs, count, batch)\n",
    "    \n",
    "print(file_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"Most Frequent Positive Words\\n\" +\n",
    "       \"============================\")\n",
    "\n",
    "for index, row in filings.iterrows():\n",
    "    pos_sorted = pd.Series(data=row.pos_occurs).sort_values(ascending=False)\n",
    "    print(\"\\n\" + row.path + \"\\n\" +\n",
    "           \"=\" * len(row.path))\n",
    "    print(pos_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Most Frequent Negative Words\\n\" +\n",
    "       \"============================\")\n",
    "\n",
    "for index, row in filings.iterrows():\n",
    "    neg_sorted = pd.Series(data=row.neg_occurs).sort_values(ascending=False)\n",
    "    print(\"\\n\" + row.path + \"\\n\" +\n",
    "           \"=\" * len(row.path))\n",
    "    print(neg_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "objs = {'filings': filings, 'processed': processed}\n",
    "for name, obj in objs.iteritems():\n",
    "    print (name, obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'distinction'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-243dfbe535cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpos_roots_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'distinction'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 'distinction'"
     ]
    }
   ],
   "source": [
    "pos_roots_dict['distinction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'distinction' in pos_list.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
